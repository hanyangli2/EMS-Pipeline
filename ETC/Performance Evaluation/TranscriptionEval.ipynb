{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base code by Sile/Mustafa; see TextCompare.py\n",
    "# Modified for multiple cases with single file by Elizabeth\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import codecs\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# stop_words = set()   # Use this line instead to run without stop words\n",
    "\n",
    "def get_transcripts(path):\n",
    "    \"\"\"\n",
    "    Separates a master file of transcripts into individual cases\n",
    "    :param path: the location of the file with all transcripts\n",
    "    :return transcripts: a list of all the transcripts\n",
    "    \"\"\"\n",
    "    file = open(path, \"r\")\n",
    "    transcripts = []\n",
    "    for thing in file:\n",
    "        transcripts.append(thing)\n",
    "    file.close()\n",
    "    return transcripts\n",
    "    \n",
    "# compare two text\n",
    "class TextComp(object):\n",
    "    def __init__(self, original_path, recognition_path, encoding='utf-8'):\n",
    "        # original_path: path of the original text\n",
    "        # recognition_path: path of the recognized text\n",
    "        # encoding: specifies the encoding which is to be used for the file\n",
    "        # all_originals: list of all individual transcripts if using master files\n",
    "        # all_recog: list of all individual transcripts if using master files\n",
    "        self.original_path = original_path\n",
    "        self.recognition_path = recognition_path\n",
    "        self.encoding = encoding\n",
    "        self.all_originals = get_transcripts(original_path)\n",
    "        self.all_recog = get_transcripts(recognition_path)\n",
    "        self.I = 0\n",
    "        self.S = 0\n",
    "        self.D = 0    \n",
    "        \n",
    "    def Preprocess(self, path, one=False):\n",
    "        if not one:\n",
    "            with codecs.open(path, encoding=self.encoding) as f:\n",
    "                text = f.read().lower().replace(\",\", \"\")\n",
    "                tokenizer = RegexpTokenizer(r'\\w+')\n",
    "                words = tokenizer.tokenize(text)\n",
    "                filtered_words = list(filter(lambda w: w not in stop_words, words))\n",
    "                return filtered_words\n",
    "        else:\n",
    "            text = path.lower()\n",
    "            tokenizer = RegexpTokenizer(r'\\w+')\n",
    "            words = tokenizer.tokenize(text)\n",
    "            filtered_words = list(filter(lambda w: w not in stop_words, words))\n",
    "            return filtered_words\n",
    "\n",
    "    def WER(self, debug=False, ind=\"all\"):\n",
    "        if ind == \"all\":\n",
    "            r = self.Preprocess(self.original_path)\n",
    "            h = self.Preprocess(self.recognition_path)\n",
    "        else:\n",
    "            r = self.Preprocess(self.all_originals[ind], True)\n",
    "            h = self.Preprocess(self.all_recog[ind], True)\n",
    "        # costs will holds the costs, like in the Levenshtein distance algorithm\n",
    "        costs = [[0 for inner in range(len(h) + 1)] for outer in range(len(r) + 1)]\n",
    "        # backtrace will hold the operations we've done.\n",
    "        # so we could later backtrace, like the WER algorithm requires us to.\n",
    "        backtrace = [[0 for inner in range(len(h) + 1)] for outer in range(len(r) + 1)]\n",
    "\n",
    "        OP_OK = 0\n",
    "        OP_SUB = 1\n",
    "        OP_INS = 2\n",
    "        OP_DEL = 3\n",
    "\n",
    "        # First column represents the case where we achieve zero\n",
    "        # hypothesis words by deleting all reference words.\n",
    "        for i in range(1, len(r) + 1):\n",
    "            costs[i][0] = i\n",
    "            backtrace[i][0] = OP_DEL\n",
    "\n",
    "        # First row represents the case where we achieve the hypothesis\n",
    "        # by inserting all hypothesis words into a zero-length reference.\n",
    "        for j in range(1, len(h) + 1):\n",
    "            costs[0][j] = j\n",
    "            backtrace[0][j] = OP_INS\n",
    "\n",
    "        # computation\n",
    "        for i in range(1, len(r) + 1):\n",
    "            for j in range(1, len(h) + 1):\n",
    "                if r[i - 1] == h[j - 1]:\n",
    "                    costs[i][j] = costs[i - 1][j - 1]\n",
    "                    backtrace[i][j] = OP_OK\n",
    "                else:\n",
    "                    substitutionCost = costs[i - 1][j - 1] + 1  # penalty is always 1\n",
    "                    insertionCost = costs[i][j - 1] + 1  # penalty is always 1\n",
    "                    deletionCost = costs[i - 1][j] + 1  # penalty is always 1\n",
    "\n",
    "                    costs[i][j] = min(substitutionCost, insertionCost, deletionCost)\n",
    "                    if costs[i][j] == substitutionCost:\n",
    "                        backtrace[i][j] = OP_SUB\n",
    "                    elif costs[i][j] == insertionCost:\n",
    "                        backtrace[i][j] = OP_INS\n",
    "                    else:\n",
    "                        backtrace[i][j] = OP_DEL\n",
    "\n",
    "        # back trace though the best route:\n",
    "        i = len(r)\n",
    "        j = len(h)\n",
    "        self.S = 0\n",
    "        self.D = 0\n",
    "        self.I = 0\n",
    "        numCor = 0\n",
    "        if debug:\n",
    "            print(\"OP\\toriginal\\trecognition\")\n",
    "            lines = []\n",
    "        while i > 0 or j > 0:\n",
    "            if backtrace[i][j] == OP_OK:\n",
    "                numCor += 1\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "                if debug:\n",
    "                    lines.append(\"OK\\t\" + r[i] + \"\\t\" + h[j])\n",
    "            elif backtrace[i][j] == OP_SUB:\n",
    "                self.S += 1\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "                if debug:\n",
    "                    lines.append(\"SUB\\t\" + r[i] + \"\\t\" + h[j])\n",
    "            elif backtrace[i][j] == OP_INS:\n",
    "                self.I += 1\n",
    "                j -= 1\n",
    "                if debug:\n",
    "                    lines.append(\"INS\\t\" + \"****\" + \"\\t\" + h[j])\n",
    "            elif backtrace[i][j] == OP_DEL:\n",
    "                self.D += 1\n",
    "                i -= 1\n",
    "                if debug:\n",
    "                    lines.append(\"DEL\\t\" + r[i] + \"\\t\" + \"****\")\n",
    "        if debug:\n",
    "            lines = reversed(lines)\n",
    "            for line in lines:\n",
    "                print(line)\n",
    "            print(\"#cor \" + str(numCor))\n",
    "            print(\"#sub \" + str(self.S))\n",
    "            print(\"#del \" + str(self.D))\n",
    "            print(\"#ins \" + str(self.I))\n",
    "            return (self.S + self.D + self.I) / float(len(r))\n",
    "        wer_result = round((self.S + self.D + self.I) / float(len(r)), 3)\n",
    "        return wer_result\n",
    "\n",
    "    def Accuracy(self, ind=\"all\"):\n",
    "        if ind == \"all\":\n",
    "            return float(len(self.Preprocess(self.original_path)) - self.D - self.S) / len(\n",
    "                self.Preprocess(self.original_path))\n",
    "        else: \n",
    "            return float(len(self.Preprocess(self.all_originals[ind], True)) - self.D - self.S) / len(\n",
    "                self.Preprocess(self.all_originals[ind], True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to use\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Instructions: Modify path to be where your files are. \n",
    "    \"master file\" = one text file with multiple transcripts, generally copied from a spreadsheet\n",
    "    If you want the individual WERs of each transcript in a master file, use WER(ind=#) in a loop with # = index numbers,\n",
    "    one for each transcript, as seen in the loop below.\n",
    "    If you want the WER for a single file or the overall WER of many files, use WER() without arguments\n",
    "    You can also get the WER of one transcript from a file with many by just using WER(ind=#) with the index of what you want.\n",
    "    -Above suggestions also apply to Accuracy; however, I, D, and S are set after the last WER, so you have to run \n",
    "        Accuracy() directly after an individual text's WER() if you want the accuracy for just that text\n",
    "    \n",
    "    Notes: -debug=True shows the word-by-word breakdown of the comparison\n",
    "           -making stop_words an empty set (see #hyper parameters) finds WER without taking stop words into account\n",
    "           -you have to run WER() before you can correctly use Accuracy()\n",
    "    \"\"\"\n",
    "    path = \"C:/Users/Student/OneDrive/Documents/Summer 2019 Research/Week 5-Clean and North Garden/NG625Eval/\"\n",
    "    \n",
    "    # Multiple WERs\n",
    "    for i in range(2):\n",
    "        compare = TextComp(path + \"mastertexttrue.txt\", path + \"mastertextresults.txt\")\n",
    "#         print(\"Recording 00\" + str(i) + \" WER: \" + str(compare.WER(ind=i, debug=True)))\n",
    "        compare.WER(ind=i)\n",
    "        print(str(compare.Accuracy(ind=i)))\n",
    "#         print()\n",
    "        \n",
    "    # Single WER\n",
    "#     compare = TextComp(path + \"singletest.txt\", path + \"singletestapi.txt\")\n",
    "#     print(str(compare.WER(debug=True)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8596491228070176\n",
      "0.8773946360153256\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
